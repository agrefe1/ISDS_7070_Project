{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 2: Identifying Promising Models & Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Andrew Grefer, Rebecca Jorgensen, Jonathan Murphy, Will Storment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create some promising models, we imported the appropriate packages, specifically sklearn so we can get accuracy scores, MSE, and R^2 scores to guide us while we tune.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_job_postings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported our dataset and wrangled it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_col = df_fake.fraudulent\n",
    "fake_model = df_fake.drop(labels = ['job_id', 'department', 'function', 'fraudulent'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_model[\"title\"].replace(np.nan, 'No title stated', inplace = True)\n",
    "fake_model[\"location\"].replace(np.nan, 'No location stated', inplace = True)\n",
    "fake_model[\"company_profile\"].replace(np.nan, 'No profile', inplace = True)\n",
    "fake_model[\"description\"].replace(np.nan, 'No description', inplace = True)\n",
    "fake_model[\"requirements\"].replace(np.nan, 'No requirements stated', inplace = True)\n",
    "fake_model[\"employment_type\"].replace(np.nan, 'Not stated', inplace = True)\n",
    "fake_model[\"required_experience\"].replace(np.nan, 'Not stated', inplace = True)\n",
    "fake_model[\"required_education\"].replace(np.nan, 'Not stated', inplace = True)\n",
    "fake_model[\"industry\"].replace(np.nan, 'No industry stated', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure these are analyzed as binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\becca\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "fake_model['salary_range'].loc[~fake_model['salary_range'].isnull()] = 1\n",
    "fake_model['salary_range'].loc[fake_model['salary_range'].isnull()] = 0 \n",
    "fake_model['benefits'].loc[~fake_model['benefits'].isnull()] = 1\n",
    "fake_model['benefits'].loc[fake_model['benefits'].isnull()] = 0 \n",
    "fake_model.rename(columns={'salary_range': 'salary_stated', 'benefits' : 'benefits_stated'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to create training and testing datasets based on the 'fraudulent' and 'description' values, we had to specifically make sure the 'description' was cast as a string type.\n",
    "\n",
    "We are trying to predict whether the description is fraudulent, so 'fraudulent' = y is our target variable\n",
    "\n",
    "We define our testing and training variables appropriately, where 'description' is our explanatory variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.replace('?', np.NaN, inplace=True)\n",
    "df_fake['description'] = df_fake['description'].astype(str) \n",
    "\n",
    "\n",
    "y = df_fake.fraudulent      \n",
    "df_fake = df_fake.drop('fraudulent', axis=1)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_fake['description'], y, test_size=0.35, random_state=53) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601     0\n",
       "5960     0\n",
       "14302    0\n",
       "14579    0\n",
       "5596     0\n",
       "2835     0\n",
       "14935    0\n",
       "15103    0\n",
       "5211     0\n",
       "6387     0\n",
       "11470    0\n",
       "13762    0\n",
       "15697    0\n",
       "16655    0\n",
       "9643     0\n",
       "9868     0\n",
       "5829     0\n",
       "8169     0\n",
       "17633    1\n",
       "2886     0\n",
       "Name: fraudulent, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601     Our client, a growing company in Danbury, CT, ...\n",
       "5960     SE1, London Bridge - Laserlife, part of the Vi...\n",
       "14302    United Cerebral Palsy of Oregon &amp; SW Washi...\n",
       "14579    The Sales Development Representative is respon...\n",
       "5596     We're on a hunt for a e-mail marketing special...\n",
       "2835     The Radio Producer shall not fail to properly ...\n",
       "14935    OgilvyOne Worldwide, Athens seeks to recruit a...\n",
       "15103    Apcera is completely re-imagining application ...\n",
       "5211     This position has two primary and overarching ...\n",
       "6387     Sounds like what you are looking for? Then app...\n",
       "11470    Shapeways is the leading 3D printing marketpla...\n",
       "13762    Babbel is constantly improving its internal pr...\n",
       "15697    Hopper is a travel startup based in Cambridge,...\n",
       "16655    Trans4u Ltd We are an International Translatio...\n",
       "9643     LCC is a great company to work, we have a very...\n",
       "9868     Play with kids, get paid for it :-)Love travel...\n",
       "5829     PeoplePerHour is the UK's leading online marke...\n",
       "8169     Solutions DeveloperOne of the nation’s largest...\n",
       "17633    Want to work in a fast-paced, dynamic environm...\n",
       "2886     ConsumerTrack is looking for a star talent to ...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a bag-of-words for the job postings.\n",
    "count_vectorizer will ignore the stop_words such as 'and', 'but', 'the'\n",
    "then we're fitting the training data, and then running it against the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english') \n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "count_test = count_vectorizer.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we instantiate a classifier, fit the classifier to the training data, create the prediction tags, calculate the accuracy score, and calculate the confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9637264301693832\n",
      "[[5887   36]\n",
      " [ 191  144]]\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB() \n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred = nb_classifier.predict(count_test) \n",
    "score = metrics.accuracy_score(y_test, pred)  \n",
    "print(score)\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])  \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with a test_size of 0.35, we found the best accuracy score from our confusion matrix to be 96.37264%\n",
    "\n",
    "(5887 + 144)/(0.35*17880) = 6031/6258 = 0.96372643 accuracy\n",
    "\n",
    "36 Type I errors\n",
    "191 Type II errors\n",
    "\n",
    "(36+191)/(0.35*17880) = 227/6258 = 0.03627357 errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv('fake_job_postings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to compare the 'description' features with the 'requirements', so we created another confusion matrix based on 'requirements'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure the 'requirements' was cast as a string type.\n",
    "\n",
    "We try to predict whether the requirements is fraudulent, so 'fraudulent' = y is our target variable\n",
    "\n",
    "We define our testing and training variables appropriately, where 'requirements' is our explanatory variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.replace('?', np.NaN, inplace=True)\n",
    "df_fake['requirements'] = df_fake['requirements'].astype(str) \n",
    "\n",
    "y = df_fake.fraudulent       \n",
    "df_fake = df_fake.drop('fraudulent', axis=1)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_fake['requirements'], y, test_size=0.35, random_state=53) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601     0\n",
       "5960     0\n",
       "14302    0\n",
       "14579    0\n",
       "5596     0\n",
       "2835     0\n",
       "14935    0\n",
       "15103    0\n",
       "5211     0\n",
       "6387     0\n",
       "11470    0\n",
       "13762    0\n",
       "15697    0\n",
       "16655    0\n",
       "9643     0\n",
       "9868     0\n",
       "5829     0\n",
       "8169     0\n",
       "17633    1\n",
       "2886     0\n",
       "Name: fraudulent, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601     Must be able to type at least 35 WPMMust have ...\n",
       "5960     You'll need to have at least 12 months office ...\n",
       "14302    A Bachelor’s Degree, or at least 1 year direct...\n",
       "14579    • Sales skills to include demonstrated phone a...\n",
       "5596     Exceptional copywriting and communication skil...\n",
       "2835     The Radio Producer shall produce, coordinate, ...\n",
       "14935    Minimum 1 year of art direction experienceExce...\n",
       "15103    Diagnose and resolve latent and systemic relia...\n",
       "5211     Master’s degree in Public Health, Health Educa...\n",
       "6387                                                   nan\n",
       "11470    2 + years experience in Product Management, Pr...\n",
       "13762    Absolute necessity: Experience in concept, des...\n",
       "15697    A qualified candidate hasA degree in Math, Sta...\n",
       "16655    In order to register you in our database, plea...\n",
       "9643     ·         Has experience on field as well as h...\n",
       "9868     University degree required. TEFL / TESOL / CEL...\n",
       "5829     Background / Experience We are less interested...\n",
       "8169     The ideal candidate will have:Bachelor’s degre...\n",
       "17633                          Clean Drug/Clean Background\n",
       "2886     Minimum 2 years experience performing in a mar...\n",
       "Name: requirements, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our bag-of-words again, but from 'requirements'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english') \n",
    "count_train = count_vectorizer.fit_transform(X_train)  \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the othe cm, we instantiate a classifier, fit the classifier to the training data, create the prediction tags, calculate the accuracy score, and calculate the confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9512623841482902\n",
      "[[5910   13]\n",
      " [ 292   43]]\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB() \n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "pred = nb_classifier.predict(count_test)  \n",
    "\n",
    "score = metrics.accuracy_score(y_test, pred) \n",
    "print(score)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0, 1])  \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with a test_size of 0.35, we found the best accuracy score from our confusion matrix to be 95.1262384%\n",
    "\n",
    "(5910 + 43)/(0.35*17880) = 5953/6258 = 0.951262384 accuracy\n",
    "\n",
    "13 Type I errors\n",
    "292 Type II errors\n",
    "\n",
    "(13+292)/(0.35*17880) = 305/6258 = 0.04873 errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin the random forest we first have to select predictors that have numeric values, and the only real ones we have are binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fake_model[['salary_stated', 'benefits_stated', 'telecommuting','has_company_logo', 'has_questions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_stated</th>\n",
       "      <th>benefits_stated</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  salary_stated benefits_stated  telecommuting  has_company_logo  \\\n",
       "0             0               0              0                 1   \n",
       "1             0               1              0                 1   \n",
       "2             0               0              0                 1   \n",
       "3             0               1              0                 1   \n",
       "4             0               1              0                 1   \n",
       "\n",
       "   has_questions  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.iloc[:12000]\n",
    "data_test = data.iloc[12000:]\n",
    "fraud_train = fraudulent_col.iloc[:12000]\n",
    "fraud_test = fraudulent_col.iloc[12000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we need to tune paramateres in order to figure out the best number of estimators and depth of our decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'n_estimators': [10, 25, 50, 75, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = GridSearchCV(model, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'bootstrap': [True],\n",
       "                         'max_depth': [2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'n_estimators': [10, 25, 50, 75, 100, 200]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.fit(data_train, fraud_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True, 'max_depth': 2, 'n_estimators': 50}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that the best model has a max depth of 2 and 50 estimators, we can now build the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=2, n_estimators=50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=50, max_depth=2, bootstrap=True)\n",
    "model.fit(data_train, fraud_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.05187344172126908\n",
      "R-Squared: 0.09981427872795734\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(fraud_test, y_pred)\n",
    "print('Mean squared error:', mse)\n",
    "r2 = r2_score(fraud_test, y_pred)\n",
    "print('R-Squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the MSE is very small which is great but so is the R-squared. For this type of problem we are trying to solve, this R-Squared may be actually very good. However, we need to try other solutions first."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
